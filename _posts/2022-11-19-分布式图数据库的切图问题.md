---
layout:     post
title:      "图数据库的切图问题"
subtitle:   "分布式图数据库"
date:       2022-11-18 10:00:00
author:     "Reverie"
catalog: false
header-style: text
tags: 
- 分布式
- 图数据库
---

# 分布式系统的基础问题

> 在分布式技术中，由于数据的存储和计算需要跨多个独立节点来实现，因此不得不涉及到一系列基础技术。在本文中我们只讨论两个：一是提供数据（和服务）的拷贝或者副本的问题；二是对于那些庞大数据的存储和计算该如何分发到各个独立节点上完成。 

##  数据的副本问题

由于是商用服务器，其硬件上的可靠性和维护远远低于主机，网线松动、硬盘损坏、电源故障在大型机房中几乎每小时都在发生，是常态；处理屏蔽这些硬件问题是分布式软件系统要解决的基本问题。一个常用的方式是为数据（和其服务）提供更多的拷贝或者副本，这些副本存在于多台商用服务器上，当一些副本发生故障时，由正常的副本继续提供服务；并且当访问压力增加时，还可以增加更多的副本来增加服务能力。此外，还需要通过一定的技术手段来保证这些副本的”一致性”，也就是每个服务器上各个副本的数据是一样的。当然，在图数据库中，副本问题也存在；其处理方式和大多数大数据、RDBMS 会较为类似。 

## 数据的切分问题

单台服务器的硬盘、内存、CPU 都是有限的，TB、PB 级别的数据通过一定的办法分发到各个服务器上，这称为“切片”。当一些请求要访问多个切片时，分布式系统要能够将这些请求拆散分发到各个正确的分片上，并将各分片的返回重新“拼装”成完整的结果。 

# 图数据中的切分问题：切图

> 在图数据库中，这个分发过程被形象的称为”切图”：就是把一个大图切成很多的小图，把对于这些小图的存储或者计算再放置在不同的服务器上。

图领域里面，”切图”是一个在技术、产品和工程上需要仔细权衡的问题。 

## 切图面临的三个问题

第一个问题，切在哪里？在大数据或者 RDBMS 中，我们根据记录或者字段来进行行切 row-based 或者列切 column-based，也可以根据 ID 规则进行切分；这些在语义和技术都比较直观。

但是图的特点是它的强连通性，一个点通过一些边，关联上了另外一些点，这些点又通过它们的邻边关联上了更多的点，对于图来说，切在哪里才是语义上直观与自然的。(如果用 RDBMS 的术语，相当于有大量的外键情况下，如何切分)。当然，也存在一些天然语义上的图切片方式，例如不同业务下的图数据。

第二个问题，如何保证切了之后，各分片的负载是大致均衡的？天然形成的图符合幂率定律——20% 的少数节点连接了 80% 的其他节点，这些少数节点也称为“超级节点”或者“稠密点”。这意味着少数超级节点关联了大多数其他的平平无奇的节点。因此可以预计含有超级节点的分片（服务器）的负载和热点会远远大于其他不含超级节点的分片。 

第三个问题，当图网络逐渐演化增长，图的分布和连通性也逐渐发生了改变，原有的切分方法逐渐失效，该如何评估和进行重分布。

# 不同图数据库的切图方式

## 1. “分布式”但不”切图”

> 典型的是 Neo4j 3.5 虽然采用了分布式的架构，但不进行图切分。

采用分布式的目的，是为了保证写入的多副本一致性和读负载能力。 

也就是说每个服务器中都保留了”全量”的图数据，因此图数据不能大于单机的内存和硬盘容量；而通过增加写副本，可以保证写入过程中单机失效问题；通过增加读副本，可以提供更多的读请求能力（不能提高写请求的能力）。 

可以看到对于前面的三个问题，这种方案在产品层面直接避免。但是理论上，这样的方案称为“分布式”并没有什么问题。 

多说一句，由于是单机，数据库意义上的 ACID 在技术上较为简单。 

[]()

 

---
layout:     post
title:      "图数据库的切图问题"
subtitle:   "分布式图数据库"
date:       2022-11-18 10:00:00
author:     "Reverie"
catalog: false
header-style: text
tags: 
- 分布式
- 图数据库
---

# 分布式系统的基础问题

> 在分布式技术中，由于数据的存储和计算需要跨多个独立节点来实现，因此不得不涉及到一系列基础技术。在本文中我们只讨论两个：一是提供数据（和服务）的拷贝或者副本的问题；二是对于那些庞大数据的存储和计算该如何分发到各个独立节点上完成。 

##  数据的副本问题

由于是商用服务器，其硬件上的可靠性和维护远远低于主机，网线松动、硬盘损坏、电源故障在大型机房中几乎每小时都在发生，是常态；处理屏蔽这些硬件问题是分布式软件系统要解决的基本问题。一个常用的方式是为数据（和其服务）提供更多的拷贝或者副本，这些副本存在于多台商用服务器上，当一些副本发生故障时，由正常的副本继续提供服务；并且当访问压力增加时，还可以增加更多的副本来增加服务能力。此外，还需要通过一定的技术手段来保证这些副本的”一致性”，也就是每个服务器上各个副本的数据是一样的。当然，在图数据库中，副本问题也存在；其处理方式和大多数大数据、RDBMS 会较为类似。 

## 数据的切分问题

单台服务器的硬盘、内存、CPU 都是有限的，TB、PB 级别的数据通过一定的办法分发到各个服务器上，这称为“切片”。当一些请求要访问多个切片时，分布式系统要能够将这些请求拆散分发到各个正确的分片上，并将各分片的返回重新“拼装”成完整的结果。 

# 图数据中的切分问题：切图

> 在图数据库中，这个分发过程被形象的称为”切图”：就是把一个大图切成很多的小图，把对于这些小图的存储或者计算再放置在不同的服务器上。

图领域里面，”切图”是一个在技术、产品和工程上需要仔细权衡的问题。 

## 切图面临的三个问题

第一个问题，切在哪里？在大数据或者 RDBMS 中，我们根据记录或者字段来进行行切 row-based 或者列切 column-based，也可以根据 ID 规则进行切分；这些在语义和技术都比较直观。

但是图的特点是它的强连通性，一个点通过一些边，关联上了另外一些点，这些点又通过它们的邻边关联上了更多的点，对于图来说，切在哪里才是语义上直观与自然的。(如果用 RDBMS 的术语，相当于有大量的外键情况下，如何切分)。当然，也存在一些天然语义上的图切片方式，例如不同业务下的图数据。

第二个问题，如何保证切了之后，各分片的负载是大致均衡的？天然形成的图符合幂率定律——20% 的少数节点连接了 80% 的其他节点，这些少数节点也称为“超级节点”或者“稠密点”。这意味着少数超级节点关联了大多数其他的平平无奇的节点。因此可以预计含有超级节点的分片（服务器）的负载和热点会远远大于其他不含超级节点的分片。 

第三个问题，当图网络逐渐演化增长，图的分布和连通性也逐渐发生了改变，原有的切分方法逐渐失效，该如何评估和进行重分布。

# 不同图数据库的切图方式

## 1. “分布式”但不”切图”

> 典型的是 Neo4j 3.5 虽然采用了分布式的架构，但不进行图切分。

采用分布式的目的，是为了保证写入的多副本一致性和读负载能力。 

也就是说每个服务器中都保留了”全量”的图数据，因此图数据不能大于单机的内存和硬盘容量；而通过增加写副本，可以保证写入过程中单机失效问题；通过增加读副本，可以提供更多的读请求能力（不能提高写请求的能力）。 

可以看到对于前面的三个问题，这种方案在产品层面直接避免。但是理论上，这样的方案称为“分布式”并没有什么问题。 

多说一句，由于是单机，数据库意义上的 ACID 在技术上较为简单。 

[](https://mmbiz.qpic.cn/mmbiz_png/crx0uzS8lVuB2mw6XujU4Zn7fFic2dSUdKP2LibqOKBIDqqofSpN94p5Uia7Bwe4YGiazLhXG24yficUzPqAwBtP4Lg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

参考文章 [Neo4j 3.5因果集群](https://medium.com/neo4j/querying-neo4j-clusters-7d6fde75b5b4)

## **2. 分布式，由用户来”切图”**

这个典型的代表是 Neo4j 4.x Fabric。根据业务情况，用户指定将每个部分的子图放在一个(组)服务器上，例如在一个集群内，E号 产品的图放在E号服务器上，N号 产品的图放在 N号 服务器上。(当然，为了服务本身的可用性，这些服务器还可以采用上文中 Causal Cluster 的方案)。在这个过程中，不论是查询还是写入，都需要用户指定要访问哪个服务。Fabric 辅助用户代理路由。这个方案和 RDBMS 的分表非常类似，用户在使用过程中自己指定要使用那个分区或者分表，”切分”这个动作，用户是有着完全的掌控。 

可以看到对于前面的三个问题，**这种方案在产品层面完全交给了用户来决定**。当然，这样的方案**也可以称为“分布式”**。 

多说一句，虽然可以保证 E 服务器内部的 ACID。但因为存在一定数量的边”横跨”两个服务器，技术上不保证这些”横跨”边操作的 ACID。 

[](https://dist.neo4j.com/wp-content/uploads/concept_fabric_example_3dbms.jpg)

参考文章 [Neo4j Fabric架构](https://neo4j.com/developer/neo4j-fabric-sharding/)

## **3. 非对等分布式，”切图”， 粗颗粒度的副本**

在这种方案中，既有多副本，也有“切图”，这两个过程也都需要少量用户的介入。 

[](https://mmbiz.qpic.cn/mmbiz_png/crx0uzS8lVuB2mw6XujU4Zn7fFic2dSUd3FJYwT31UVkZtKicQJ9en67BVww6qLPmRDia1oHfzuh9MqWGToIcGXtQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

在 TigerGraph 的方案中，点和边（在编码后）会分散到多个分片上。上面的三个问题，第 1 和 2 可以通过编码部分的技巧来部分缓解，并将部分查询或者计算的决策（单机还是分布式模型）交给用户决定来实现权衡。 

参考视频 [tiger Graph 切图](https://www.youtube.com/watch?v=pxtVJSpERgk)

## **4. 全对等分布式，”切图”，细颗粒度的副本**

这个方案的架构设计目的中，把图的扩展性/弹性排在整个系统设计最高的优先级。其假设是数据产生的速度快于摩尔定律，而数据之间的交互与关系又指数级高于数据产生的速度。因此必须要能够处理这样爆炸增长的数据，并快速提供服务。 

在这种架构中，通常的显著特点是把存储层和计算层物理上分开(存算分离)，各自实现细颗粒度的扩容能力； 

数据分片由存储层负责，通常用 hash 或者一致性 hash 的方案进行切分，根据点的 ID 或者主键进行散列。

比如NebulaGraph的架构

[](https://mmbiz.qpic.cn/mmbiz_png/crx0uzS8lVuB2mw6XujU4Zn7fFic2dSUd2p2mCmRQ2cAPEavia3VlGUEyuQmniafQ9iakPmgRP3jtpakicwwHZ0gp0g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

ByteGraph的架构：

[](https://mmbiz.qpic.cn/mmbiz_png/crx0uzS8lVuB2mw6XujU4Zn7fFic2dSUd84VOEeiao8PeWp0G4kTXmXicFOqlf2SUwdlibMazC8YqbSN6M8hsP1zYw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)